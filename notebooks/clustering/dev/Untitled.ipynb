{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "from algom import configs\n",
    "from algom.model_metadata import modelMetadata\n",
    "from algom.feature_importance import featureImportance\n",
    "from algom.model_plots import modelPlots\n",
    "from algom.utils.data_object import dataObject\n",
    "from algom.model_storage import modelStorage\n",
    "\n",
    "from datetime import datetime\n",
    "import hashlib\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import explained_variance_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_PROJECT_ID = configs.GOOGLE_PROJECT_ID\n",
    "METDATA_TABLE = configs.METDATA_TABLE\n",
    "PARAMETERS_TABLE = configs.PARAMETERS_TABLE\n",
    "PREDICTION_TABLE = configs.PREDICTION_TABLE\n",
    "EVALUATION_TABLE = configs.EVALUATION_TABLE\n",
    "PERFORMANCE_TABLE = configs.PERFORMANCE_TABLE\n",
    "FEATURE_IMPORTANCE_TABLE = configs.FEATURE_IMPORTANCE_TABLE\n",
    "STORAGE_TABLE = configs.STORAGE_TABLE\n",
    "QUERY_TABLE = configs.QUERY_TABLE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class modelCluster():\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data,\n",
    "        outcome,\n",
    "        model_id=None,\n",
    "        model=None,\n",
    "        index_features=None,\n",
    "        omit_features=[],\n",
    "        to_bq=False\n",
    "    ):\n",
    "        \"\"\"modelRegression\n",
    "\n",
    "        Predicts an outcome, given a model_execution_id and a data input.\n",
    "        The data input can be any data type accepted by algom's dataObject\n",
    "        class.\n",
    "\n",
    "        Args:\n",
    "            data: Accepts any data type accepted by algom's dataObject class\n",
    "\n",
    "            outcome (str): Name of the outcome variable.\n",
    "\n",
    "        TO DO: Complete docstrings\n",
    "\n",
    "        \"\"\"\n",
    "        # model data and outcome\n",
    "        self.data = dataObject(data)\n",
    "        self.outcome = outcome\n",
    "        self.model_id = model_id\n",
    "        self.model = self._get_model(\n",
    "            model_id=model_id, model=model)\n",
    "\n",
    "        # model parameters\n",
    "        self.test_size = .7\n",
    "        self.random_state = 0\n",
    "\n",
    "        # model metadata\n",
    "        self.index_features = self._set_index_features(index_features)\n",
    "        self.omit_features = omit_features\n",
    "        self.feature_list = self.get_feature_list()\n",
    "        self.model_name = None\n",
    "        self.model_description = None\n",
    "        self.to_bq = to_bq\n",
    "\n",
    "        # initialize output dataframes\n",
    "        self.predictions = None\n",
    "        self.evaluations = None\n",
    "        self.performance = None\n",
    "        self.execution_started_at = None\n",
    "\n",
    "        # table parameters\n",
    "        self.project_id = GOOGLE_PROJECT_ID\n",
    "        self.metadata_table = METDATA_TABLE\n",
    "        self.parameters_table = PARAMETERS_TABLE\n",
    "        self.predictions_table = PREDICTION_TABLE\n",
    "        self.evaluations_table = EVALUATION_TABLE\n",
    "        self.performance_table = PERFORMANCE_TABLE\n",
    "        self.feature_importance_table = FEATURE_IMPORTANCE_TABLE\n",
    "        self.storage_table = STORAGE_TABLE\n",
    "        self.query_table = QUERY_TABLE\n",
    "        print(\n",
    "            \"Initialized model. As a next step, \"\n",
    "            \"run self.predict() or self.train().\"\n",
    "        )\n",
    "\n",
    "    # DATA PREP FUNCTIONS\n",
    "    def _time_function(self, function):\n",
    "        self.execution_started_at = datetime.now()\n",
    "        f = function\n",
    "        self.execution_ended_at = datetime.now()\n",
    "        self.execution_run_time = self.execution_ended_at - \\\n",
    "            self.execution_started_at\n",
    "        return f\n",
    "\n",
    "    def _get_hash_id(self, data):\n",
    "        \"\"\"Create SHA1 hash ID from any data input\"\"\"\n",
    "        x = str(data).encode()\n",
    "        gid = hashlib.sha1(x).hexdigest()\n",
    "        return gid\n",
    "\n",
    "    def _get_class_attributes(self, cls):\n",
    "        return {k: v for k, v in cls.__dict__.items() if k[:1] != '_' and k[-1] != '_'}\n",
    "\n",
    "    def _get_model_ids(self, model_execution_type=None):\n",
    "        \"\"\"Add key model metadata to any model instance. Keeps model_id and\n",
    "        model_execution_id if they already exist in the model_object.\n",
    "        Ensures model IDs are generated consistently. Model metadata includes:\n",
    "            - model_execution_id\n",
    "            - model_id\n",
    "            - model_parameter_id\n",
    "            - model_data_id\n",
    "            - model_execution_type\n",
    "        \"\"\"\n",
    "        execution_started_at = self.execution_started_at or datetime.now()\n",
    "        model_attributes = self._get_class_attributes(self.model)\n",
    "\n",
    "        # Model ID is based on (1) the model type, (2) the model parameters\n",
    "        # (3) the outcome variable, and (4) the features used.\n",
    "        #self.model_id = self.model_id or self._get_hash_id(\n",
    "        self.model_id = self.model_id if model_execution_type=='predict' else self._get_hash_id(\n",
    "            str(self.outcome) +\n",
    "            str(self.model) +\n",
    "            str(self.data.data_id) +\n",
    "            str(self.feature_list)\n",
    "        )\n",
    "\n",
    "        # Model Execution ID is based on (1) the model type, \n",
    "        # (2) the model parameters, (3) the outcome variable, \n",
    "        # and (4) the features used.\n",
    "        self.model_execution_id = self._get_hash_id(\n",
    "            str(execution_started_at) +\n",
    "            str(self.outcome) +\n",
    "            str(self.model) +\n",
    "            str(self.data.data_id) +\n",
    "            str(self.feature_list)\n",
    "        )\n",
    "        self.model_parameter_id = self._get_hash_id(self.model)\n",
    "        self.model_data_id = self.data.data_id\n",
    "        self.model_execution_type = model_execution_type\n",
    "\n",
    "    def _get_model(self, model_id=None, model=None):\n",
    "        \"\"\"Get model if it isn't already available.\"\"\"\n",
    "        if model:\n",
    "            return model\n",
    "        elif model_id:\n",
    "            storage = modelStorage()\n",
    "            return storage.get_model_from_storage(self.model_id)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def _set_index_features(self, index_features):\n",
    "        if index_features:\n",
    "            index_features = [\n",
    "                f for f in index_features if f in list(self.data.df)]\n",
    "        else:\n",
    "            index_features = []\n",
    "        return index_features\n",
    "\n",
    "    def get_feature_list(self):\n",
    "        feature_list = [\n",
    "            f for f in list(self.data.df) if f not in\n",
    "            ([self.outcome] + self.index_features + self.omit_features)]\n",
    "        # Load to dict to ensure output order is correct\n",
    "        x = {}\n",
    "        for feature in feature_list:\n",
    "            x[feature] = None\n",
    "        return list(x.keys())\n",
    "\n",
    "    def get_feature_sets(self, test_size=None, random_state=None, **kwargs):\n",
    "        \"\"\"Use Skicit-learn to split data into training and testing sets.\n",
    "        Adds test/train versions of these tables:\n",
    "            - featues\n",
    "            - outputs\n",
    "            - outcomes\n",
    "        \"\"\"\n",
    "        self.outputs = self.data.df[\n",
    "            self.index_features + [self.outcome]]\n",
    "        self.outcomes = self.data.df[[self.outcome]]\n",
    "        self.features = self.data.df[self.feature_list]\n",
    "#         test_features, train_features, test_outputs, train_outputs \\\n",
    "#             = train_test_split(\n",
    "#                 self.features,\n",
    "#                 self.outputs,\n",
    "#                 test_size=test_size or self.test_size,\n",
    "#                 random_state=random_state or self.random_state)\n",
    "#         self.train_features = train_features\n",
    "#         self.test_features = test_features\n",
    "#         self.train_outputs = train_outputs\n",
    "#         self.test_outputs = test_outputs\n",
    "#         self.train_outcomes = train_outputs[self.outcome]\n",
    "#         self.test_outcomes = test_outputs[self.outcome]\n",
    "\n",
    "    def _get_clean_output_dataframe(\n",
    "        self,\n",
    "        input_dataframe,\n",
    "        model_execution_type\n",
    "    ):\n",
    "        \"\"\"Get a standardized output for metadata tables, including\n",
    "        - self.metadata_table\n",
    "        - self.parameter_table\n",
    "        - self.queries_table\n",
    "        \"\"\"\n",
    "        # Create metadata\n",
    "        md_index = {}\n",
    "        md_index['model_id'] = self.model_id\n",
    "        md_index['model_execution_id'] = self.model_execution_id\n",
    "        md_index['model_parameter_id'] = self.model_parameter_id\n",
    "        md_index['model_data_id'] = self.data.data_id\n",
    "        md_index['execution_started_at'] = self.execution_started_at if \\\n",
    "            hasattr(self, 'execution_started_at') else None\n",
    "        md_index['execution_ended_at'] = self.execution_ended_at if \\\n",
    "            hasattr(self, 'execution_ended_at') else None\n",
    "        md_index['execution_run_time'] = self.execution_run_time if \\\n",
    "            hasattr(self, 'execution_run_time') else None\n",
    "        md_index['model_execution_type'] = model_execution_type\n",
    "        md_index['model_outcome'] = self.outcome\n",
    "\n",
    "        # Merge input dataset onto metadata\n",
    "        df_index = DataFrame.from_dict(md_index, orient='index').T\n",
    "        input_dataframe['model_execution_id'] = self.model_execution_id\n",
    "        df_output = df_index.merge(\n",
    "            input_dataframe,\n",
    "            how='inner',\n",
    "            on='model_execution_id',\n",
    "            suffixes=('_drop', '')\n",
    "        )\n",
    "        column_list = [h for h in list(df_output) if '_drop' not in h]\n",
    "        df_output = df_output[column_list]\n",
    "        return df_output\n",
    "\n",
    "    # DATA I/O\n",
    "\n",
    "    def load_to_bq(self):\n",
    "        \"\"\"Load model outputs to BigQuery:\n",
    "            - model_metadata\n",
    "            - predictions\n",
    "            - performance\n",
    "            - feature_importance\n",
    "\n",
    "        <<<<<< UPDATE THIS: USE os.exist() INSTEAD >>>>>>>\n",
    "        \"\"\"\n",
    "        def _check_and_load(df, table_name):\n",
    "            if df:\n",
    "                dataObject(df).to_db(\n",
    "                    destination_table=table_name,\n",
    "                    project_id=GOOGLE_PROJECT_ID,\n",
    "                    table_partition=None,\n",
    "                    table_params=None,\n",
    "                    if_exists='append'\n",
    "                )\n",
    "            else:\n",
    "                print('{} does not exist. Skipping.'.format(table_name))\n",
    "\n",
    "        _check_and_load(self.predictions, self.predictions_table)\n",
    "        _check_and_load(self.evaluations, self.evaluations_table)\n",
    "        _check_and_load(self.performance, self.performance_table)\n",
    "        _check_and_load(self.metadata.metadata, self.metadata_table)\n",
    "        _check_and_load(self.metadata.parameters, self.parameters_table)\n",
    "        _check_and_load(self.feature_importance.feature_importance,\n",
    "                        self.feature_importance_table)\n",
    "        print(\"COMPLETE: all model outputs have been loaded to BigQuery!\")\n",
    "\n",
    "    \"\"\" MODELING\n",
    "\n",
    "    Functions used in training models. Includes:\n",
    "        - predict\n",
    "        - evaluate\n",
    "        - save\n",
    "    \"\"\"\n",
    "\n",
    "    # PREDICTION\n",
    "\n",
    "    def predict(self):\n",
    "        \"\"\"Output predictions to dataframe based on the Scikit Learn\n",
    "        model provided. Uses all technical_analysis from the input dataset to\n",
    "        generate predictions. Generates metadata about the model prediction\n",
    "        execution.\n",
    "\n",
    "        Attributes\n",
    "        ----------\n",
    "        outputs\n",
    "            DataFrame; Dataframe containing single column of outputs.\n",
    "            Not all entries need to have outcomes.\n",
    "\n",
    "        technical_analysis\n",
    "            DataFrame; Dataframe of technical_analysis to run prediction.\n",
    "\n",
    "        to_bq\n",
    "            Boolean; If True then push to BigQuery.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        predictions   DataFrame; Dataframe of predictions and\n",
    "            outcomes (if available).\n",
    "        \"\"\"\n",
    "        def _set_model_features(model_object):\n",
    "            \"\"\"Return datasets needed for prediction.\"\"\"\n",
    "            model_object.get_feature_sets()\n",
    "            self.outputs = model_object.outputs\n",
    "            self.features = model_object.features[self.get_feature_list()]\n",
    "            self.outcomes = model_object.outcomes\n",
    "\n",
    "        def _get_model_predictions():\n",
    "            \"\"\"Output dataframe with prediction outputs.\"\"\"\n",
    "            _set_model_features(self)\n",
    "            self.predictions = pd.Series(\n",
    "                self.model.predict(self.features), name='predictions')\n",
    "            df_predictions = self._get_prediction_df(\n",
    "                self.outputs, self.outcomes, self.predictions)\n",
    "            df_predictions = self._get_clean_output_dataframe(\n",
    "                df_predictions, 'predict')\n",
    "            return df_predictions\n",
    "\n",
    "        def _load_to_bq():\n",
    "            dataObject(self.predictions).to_db(\n",
    "                destination_table=self.predictions_table,\n",
    "                project_id=GOOGLE_PROJECT_ID,\n",
    "                table_partition=None,\n",
    "                table_params=None,\n",
    "                if_exists='append')\n",
    "\n",
    "        # Get feature and outcome data\n",
    "        self._get_model_ids(model_execution_type='predict')\n",
    "        self.predictions = self._time_function(_get_model_predictions())\n",
    "        self.metadata = modelMetadata(self)\n",
    "\n",
    "        # Get model performance\n",
    "        print('Get model performance.')\n",
    "        self.get_performance()\n",
    "        self.plots = modelPlots(self)\n",
    "\n",
    "        # Load to BigQuery\n",
    "        if self.to_bq:\n",
    "            _load_to_bq()\n",
    "\n",
    "    # TRAINING\n",
    "\n",
    "    def train(self, model):\n",
    "        \"\"\"Fit a Scikit Learn model to a given feature set, and get\n",
    "        metadata related to the training execution.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        model : Scikit Learn model\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self.query.metadata : pandas.DataFrame()\n",
    "            Dataframe containing metadata related to the model execution\n",
    "        \"\"\"\n",
    "        def _set_model_features(model_object):\n",
    "            # Get training feature set\n",
    "            model_object.get_feature_sets()\n",
    "            self.features = self.train_features[self.get_feature_list()]\n",
    "            self.outcomes = self.train_outcomes\n",
    "\n",
    "        def _train_model(model_object):\n",
    "            _set_model_features(model_object)\n",
    "            self.model.fit(self.features, self.outcomes)\n",
    "\n",
    "        # Train model\n",
    "        print('Training model on {}.'.format(self.outcome))\n",
    "        self.model = model\n",
    "        self._get_model_ids(model_execution_type='train')\n",
    "        self._time_function(_train_model(self))\n",
    "\n",
    "        # Add model IDs and metadata to class\n",
    "        self.metadata = modelMetadata(self)\n",
    "\n",
    "        # Get model feature importance\n",
    "        self.feature_importance = featureImportance(self)\n",
    "        print('Fit model in {}.'.format(self.execution_run_time))\n",
    "\n",
    "        # Get model performance\n",
    "        print('Get model performance.')\n",
    "        self._evaluate()\n",
    "        self.get_performance()\n",
    "        self.plots = modelPlots(self)\n",
    "\n",
    "    # EVALUATION\n",
    "\n",
    "    def _evaluate(self):\n",
    "        \"\"\"Once a model has been trained, perform a validation\n",
    "        and output the predictions to a dataframe.\n",
    "\n",
    "        Steps:\n",
    "        - predict the test technical_analysis\n",
    "        - generate evaluations dataframe\n",
    "        - collect model metadata\n",
    "        - load evaluations table to BQ if to_bq==True\n",
    "        \"\"\"\n",
    "        def _get_test_model_features(model_object):\n",
    "            model_object.get_feature_sets()\n",
    "            outputs = model_object.test_outputs\n",
    "            features = model_object.test_features[self.get_feature_list()]\n",
    "            outcomes = model_object.test_outcomes\n",
    "            return outputs, features, outcomes\n",
    "\n",
    "        def _get_model_evaluations():\n",
    "            [outputs, features, outcomes] = _get_test_model_features(self)\n",
    "            evaluations = pd.Series(\n",
    "                self.model.predict(features), name='evaluations')\n",
    "            df_evaluations = self._get_prediction_df(\n",
    "                outputs, outcomes, evaluations)\n",
    "            df_evaluations = self._get_clean_output_dataframe(\n",
    "                df_evaluations, 'evaluations')\n",
    "            return df_evaluations\n",
    "\n",
    "        if self.model:\n",
    "            self.evaluations = _get_model_evaluations()\n",
    "            print('Set evaluation to self.evaluations in {}.'.format(\n",
    "                self.execution_run_time))\n",
    "            # load to BigQuery\n",
    "            if self.to_bq:\n",
    "                dataObject(self.evaluations).to_db(\n",
    "                    destination_table=self.evaluations_table,\n",
    "                    project_id=GOOGLE_PROJECT_ID,\n",
    "                    table_partition=None,\n",
    "                    table_params=None,\n",
    "                    if_exists='append'\n",
    "                )\n",
    "\n",
    "    # STORAGE\n",
    "    def save(self):\n",
    "        self.storage = modelStorage(self)\n",
    "        self.storage.pickle_model(to_gcs=True)\n",
    "        print(\"Saved model to Google Storage:\\n\\t{}\".format(\n",
    "            self.storage.model_storage_filepath))\n",
    "\n",
    "    # PERFORMANCE\n",
    "    def get_performance(self):\n",
    "        \"\"\" Get performance metrics, if possible when predicting\n",
    "        future outcomes; otherwise, leave blank.\n",
    "        \"\"\"\n",
    "        self._get_rsquared()\n",
    "        self._get_mean_errors()\n",
    "        data = {\n",
    "            'rsquared': self.rsquared,\n",
    "            'mae': self.mean_abs_error,\n",
    "            'error_variance': self.error_var}\n",
    "        df_performance = pd.DataFrame.from_dict(data=data, orient='index')\n",
    "        df_performance = df_performance.reset_index()\n",
    "        df_performance.columns = ['parameter', 'value']\n",
    "        df_performance = self._get_clean_output_dataframe(\n",
    "            df_performance, 'performance')\n",
    "        self.performance = df_performance\n",
    "        print('Performance metrics added to `self.performance`')\n",
    "\n",
    "        # load performance to BigQuery\n",
    "        self._print_performance()\n",
    "        if self.to_bq:\n",
    "            pass\n",
    "\n",
    "            # <<<<<<<<<< FIX THIS !!! >>>>>>>>>>>>\n",
    "\n",
    "#             dataObject(self.performance).to_db(\n",
    "#                 destination_table=self.performance_table,\n",
    "#                 project_id=GOOGLE_PROJECT_ID,\n",
    "#                 table_partition=None,\n",
    "#                 table_params=None,\n",
    "#                 if_exists='append'\n",
    "#             )\n",
    "\n",
    "    # ANALYSIS\n",
    "\n",
    "    def get_correlations(self):\n",
    "        correlations = pd.DataFrame(self.df.corr()[self.outcome])\n",
    "        correlations = correlations.rename(\n",
    "            columns={self.outcome: 'correlation'})\n",
    "        correlations['abs_correlation'] = abs(correlations['correlation'])\n",
    "        correlations = correlations.sort_values(\n",
    "            'abs_correlation', ascending=False)\n",
    "        self.correlations = correlations[\n",
    "            correlations.index.isin(self.feature_list)]\n",
    "        return self.correlations\n",
    "\n",
    "    def _get_correlation_order(self):\n",
    "        correlations = self.get_correlations()\n",
    "        correlations_dict = correlations.to_dict()\n",
    "        correlations_dict = correlations_dict['correlation']\n",
    "        correlations_order = list(correlations_dict.keys())\n",
    "        return correlations_order\n",
    "\n",
    "    def _get_prediction_df(self, outputs, outcomes, predictions):\n",
    "        \"\"\"Reformat predict outputs into a single dataframe\"\"\"\n",
    "\n",
    "        # convert outputs to a dataframe\n",
    "        predictions = pd.DataFrame(predictions)\n",
    "        outputs = pd.DataFrame(outputs).reset_index().drop(\n",
    "            'index', 'columns')\n",
    "        outcomes = pd.DataFrame(outcomes).reset_index().drop(\n",
    "            'index', 'columns')\n",
    "\n",
    "        # ensure columns are labeled properly\n",
    "        predictions.columns = ['predictions']\n",
    "        outcomes.columns = ['outcomes']\n",
    "        results = pd.concat(\n",
    "            [outputs, predictions, outcomes], axis=1, sort=False)\n",
    "        results['errors'] = results['outcomes'] - results['predictions']\n",
    "        results = results.drop(self.outcome, 'columns')\n",
    "        return results\n",
    "\n",
    "    def _get_predictions_or_evaluations(self):\n",
    "        \"\"\"If class has predictions, get it. Otherwise, get evaluations.\"\"\"\n",
    "        if isinstance(self.predictions, DataFrame):\n",
    "            df = self.predictions\n",
    "        elif isinstance(self.evaluations, DataFrame):\n",
    "            df = self.evaluations\n",
    "        else:\n",
    "            df = pd.DataFrame()\n",
    "        return df\n",
    "\n",
    "    def _get_rsquared(\n",
    "        self,\n",
    "        outcome_var='outcomes',\n",
    "        prediction_var='predictions'\n",
    "    ):\n",
    "        try:\n",
    "            df_predict = self._get_predictions_or_evaluations()\n",
    "            outcomes = df_predict[outcome_var]\n",
    "            predictions = df_predict[prediction_var]\n",
    "            self.rsquared = explained_variance_score(outcomes, predictions)\n",
    "            print('Set R^2 to `self.rsquared`')\n",
    "        except Exception as e:\n",
    "            self.rsquared = np.NaN\n",
    "            print('R-Squared cannot be calculated.\\n{}'.format(e))\n",
    "\n",
    "    def _get_mean_errors(self):\n",
    "        df_predict = self._get_predictions_or_evaluations()\n",
    "        try:\n",
    "            mean_abs_error = df_predict['errors'].abs().mean()\n",
    "            mao = df_predict['outcomes'].abs().mean()\n",
    "            mean_abs_pct_error = mean_abs_error / mao\n",
    "            # ^^^^ CONFIRM CALCULATION OF MAE ^^^^\n",
    "            error_var = df_predict['errors'].var()\n",
    "            self.mean_abs_error = round(mean_abs_error, 8)\n",
    "            self.mean_abs_outcome = round(mao, 8)\n",
    "            self.mean_abs_pct_error = round(mean_abs_pct_error, 8)\n",
    "            self.error_var = round(error_var, 8)\n",
    "            print(\"\"\"The following performance measures have been added:\n",
    "                - self.mean_abs_error\n",
    "                - self.mean_abs_outcome\n",
    "                - self.mean_abs_pct_error\n",
    "                - self.error_var\n",
    "            \"\"\")\n",
    "        except Exception as e:\n",
    "            self.mean_abs_error = np.NaN\n",
    "            self.mean_abs_outcome = np.NaN\n",
    "            self.mean_abs_pct_error = np.NaN\n",
    "            self.error_var = np.NaN\n",
    "            print('Performance metrics cannot be calculated.\\n{}'.format(e))\n",
    "\n",
    "    def _print_performance(self):\n",
    "        print(\"\"\"\\nMODEL PERFORMANCE SUMMARY\n",
    "        - Mean Absolute Error:\\t {}\n",
    "        - Mean Absolute Outcome:\\t {}\n",
    "        - Mean Absolute Percent Error:\\t {}\n",
    "        - Error Variance:\\t {}\n",
    "        - R-Squared:\\t\\t {}\n",
    "        \"\"\".format(\n",
    "            round(self.mean_abs_error, 5),\n",
    "            round(self.mean_abs_outcome, 5),\n",
    "            round(self.mean_abs_pct_error, 5),\n",
    "            round(self.error_var, 5),\n",
    "            round(self.rsquared, 5),\n",
    "        ))\n",
    "        print(\"PLOT PREDICTIONS: Use the following commands\"\n",
    "              \"to view model performance.\"\n",
    "              \"\"\"\n",
    "              `self.plot_predictions_by_date(start_date, end_date)`\n",
    "              `self.plot_predictions_histogram(start_date, end_date)`\n",
    "              `self.plot_errors_by_date(start_date, end_date)`\n",
    "              `self.plot_errors_histogram(start_date, end_date)`\n",
    "              `self.plot_predictions_scatterplot(start_date, end_date)`\n",
    "              \"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
